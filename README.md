游닍 Configuraci칩n Requerida para el Cluster en Databricks Community Edition
Librer칤as a instalar (para ETL en streaming con Kafka + Snowflake):

Tipo	Librer칤a/Paquete	M칠todo de Instalaci칩n	Notas
Maven	net.snowflake:spark-snowflake_2.12:2.11.0	Pesta침a "Libraries" > Install > Maven	Ajustar versi칩n (2.12) seg칰n tu Runtime
Maven	net.snowflake:snowflake-jdbc:3.14.0	Pesta침a "Libraries" > Install > Maven	Requerido para el conector Spark-Snowflake
PyPI	snowflake-connector-python==3.2.0	Notebook: %pip install snowflake-connector-python==3.2.0	Para operaciones con Python
PyPI	spark-sql-kafka-0-10_2.12==3.5.0	Notebook: %pip install spark-sql-kafka-0-10_2.12==3.5.0	Conector para Kafka
PyPI	pyarrow==10.0.1	Notebook: %pip install pyarrow==10.0.1	Manejo eficiente de datos
游늷 Pasos para Instalaci칩n:
Crear un cluster:

Runtime recomendado: Databricks Runtime 11.3 LTS (compatible con las librer칤as mencionadas).

Tipo: Single Node (Community Edition solo permite esto).

Instalar librer칤as Maven:

Ir a la pesta침a "Libraries" en la configuraci칩n del cluster.

Hacer clic en "Install New" > Seleccionar "Maven".

Pegar las coordenadas de Maven (ver tabla arriba).

Instalar librer칤as PyPI:

Abrir un nuevo notebook conectado al cluster.

Ejecutar los comandos %pip install indicados en la tabla.

Reiniciar el cluster despu칠s de instalar.

Verificar instalaci칩n:

python
Copy
spark.sparkContext.listPackages()  # Mostrar치 las librer칤as instaladas
丘멆잺 Notas importantes:
En Community Edition, las librer칤as se pierden al terminar el cluster. Debes reinstalarlas en cada nueva sesi칩n.

Espacio limitado: Evita instalar librer칤as innecesarias (solo las de la tabla).

Si falla la instalaci칩n por Maven, usa el m칠todo alternativo con c칩digo en un notebook (te comparto el ejemplo si lo necesitas).

游늭 Documentaci칩n de referencia:
Conector Snowflake para Spark

Conector Kafka para Spark